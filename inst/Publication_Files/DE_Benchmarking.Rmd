---
title: "DE Assumption Testing"
output: html_document
date: "2025-06-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#General Libraries
library(SpaMTP)
library(Cardinal)
library(Seurat)
library(dplyr)

#For plotting + DE plots
library(ggplot2)
library(EnhancedVolcano)
```


```{r}
bladder <- readRDS("vignettes/vignette_data_files/Mouse_Urinary_Bladder/bladder_annotated.RDS")
ROI <- subset(bladder, subset = ssc %in% c("2", "5", "6"))
```

```{r}
## Check for normal distibution
expr <- ROI@assays$Spatial$counts
genes <- rownames(ROI@assays$Spatial$counts)
shapiro_safe <- function(vals, max_n = 5000) {
  vals <- vals[!is.na(vals)]  # remove NAs
  if (length(unique(vals)) < 3) {
    return(NA)  # not enough variation
  }
  if (length(vals) > max_n) {
    vals <- sample(vals, max_n)
  }
  return(shapiro.test(vals)$p.value)
}

shapiro_p <- sapply(rownames(expr), function(g) {
  vals <- as.numeric(expr[g, ])
  shapiro_safe(vals)
})

qqnorm(as.numeric(expr[genes[50], ]), main = paste("Q-Q Plot of", genes[50]))
qqline(as.numeric(expr[genes[50], ]), col = "red")

```

shapiro_p
                    Category Count
1     p <= 0.05 (Not Normal)    79
2 p > 0.05 (Possibly Normal)     0



Method     Continous Data    Normality?	    Your Data OK?	          Notes
t-test	        ✅ Yes	        ❌             No	                  Violated assumption — don't use for raw or count-based data.
wilcox	        ✅ Yes	        ✅             Yes	                  Non-parametric, safe and robust.
MAST	          ✅ Yes	        ✅             Yes                  	Models dropout explicitly, good for scRNA-seq.
negbinom        ❌ No	        ✅             No                   	OK for UMI count data.
DESeq2	        ❌ No	        ✅             No                   	Uses negative binomial, robust.
poisson	        ❌ No	     Assumes Poisson	 No	                   Often too simplistic.
LR	            ✅ Yes	        ✅             Yes	                  Logistic regression on group membership.
roc	            ✅ Yes	        ✅             Yes	                  Measures predictive power, not dependent on distribution.
wilcox_limma	  ✅ Yes	        ✅             Yes                 	limma wrapper, does not assume normality.
bimod	          ✅ Yes         ✅             Yes                 	LRT based, flexible.




```{r}
library(ggvenn)
library(dplyr)
library(ggplot2)
library(purrr)

pool_sizes <- 1:20
seeds <- c(8880, 4512, 3291, 10, 30)  # number of repetitions per pool size

# Run DEMs multiple times per pool size
results <- expand.grid(pool_n = pool_sizes, rep = 1:length(seeds)) %>%
  pmap_dfr(function(pool_n, rep) {
    de <- FindAllDEMs(ROI, ident = "ssc", n = pool_n, seed = seeds[rep])
    de$DEMs %>%
      mutate(pool_n = pool_n, rep = rep)
  })

# Count significant DEMs (FDR < 0.05) per pool size, cluster, and rep
sig_counts <- results %>%
  filter(FDR < 0.05) %>%
  group_by(pool_n, cluster, rep) %>%
  summarise(num_significant = n(), .groups = "drop")

# Summarise across reps: mean ± sd
sig_summary <- sig_counts %>%
  group_by(pool_n, cluster) %>%
  summarise(
    mean_sig = mean(num_significant),
    sd_sig = sd(num_significant),
    se_sig = sd_sig / sqrt(n()),
    .groups = "drop"
  )

# Plot with error bars
ggplot(sig_summary, aes(x = pool_n, y = mean_sig, colour = as.factor(cluster))) +
  geom_line() +
  geom_point() +
  #geom_ribbon(aes(ymin = mean_sig - se_sig, ymax = mean_sig + se_sig, fill = as.factor(cluster)), alpha = 0.2, colour = NA)+
  geom_errorbar(aes(ymin = mean_sig - se_sig, ymax = mean_sig + se_sig), width = 0.3) +
  labs(
    title = "Number of Significant DEMs vs Pool Size (Mean ± SE)",
    x = "Number of Pools (n)",
    y = "Mean Significant DEMs (FDR < 0.05)",
    colour = "Cluster"
  ) +
  theme_classic()



# Step 1: Get sets of sig m/z per (pool_n, cluster, rep)
sig_sets <- results %>%
  filter(FDR < 0.05) %>%
  group_by(pool_n, cluster, rep) %>%
  summarise(sig_mz = list(gene), .groups = "drop")

# Step 2: Compute intersection across replicates for each (pool_n, cluster)
consistency_summary <- sig_sets %>%
  group_by(pool_n, cluster) %>%
  summarise(
    shared_mz = reduce(sig_mz, intersect),
    num_shared = length(shared_mz),
    .groups = "drop"
  )

# Step 3: Plot
ggplot(consistency_summary, aes(x = pool_n, y = num_shared, colour = as.factor(cluster))) +
  geom_line() +
  geom_point() +
  labs(
    title = "Number of Shared Significant m/z Across Replicates",
    x = "Number of Pools (n)",
    y = "Shared m/z (FDR < 0.05) Across All Seeds",
    colour = "Cluster"
  ) +
  theme_classic()


library(dplyr)
library(tidyr)
library(purrr)
library(reshape2)
library(ggplot2)

# Set how many genes to consider for comparison
top_n <- 20

# Get top N DE genes for each (cluster, pool_n, rep)
top_genes_by_group <- results %>%
  group_by(cluster, pool_n, rep) %>%
  arrange(FDR) %>%
  slice_head(n = top_n) %>%
  summarise(genes = list(gene), .groups = "drop")

# Function to compute average Jaccard between all replicates from two pool sizes
compute_pool_jaccard <- function(pool1_genes, pool2_genes) {
  intersect_size <- length(intersect(pool1_genes, pool2_genes))
  union_size <- length(union(pool1_genes, pool2_genes))
  if (union_size == 0) return(NA)
  intersect_size / union_size
}

# For each cluster, compute Jaccard similarity matrix
similarity_matrices <- top_genes_by_group %>%
  split(.$cluster) %>%
  map(~{
    df <- .x
    pool_sizes <- unique(df$pool_n)
    
    mat <- matrix(NA, nrow = length(pool_sizes), ncol = length(pool_sizes),
                  dimnames = list(pool_sizes, pool_sizes))
    
    for (i in seq_along(pool_sizes)) {
      for (j in seq_along(pool_sizes)) {
        genes1 <- df %>% filter(pool_n == pool_sizes[i]) %>% pull(genes) %>% unlist()
        genes2 <- df %>% filter(pool_n == pool_sizes[j]) %>% pull(genes) %>% unlist()
        mat[i, j] <- compute_pool_jaccard(genes1, genes2)
      }
    }
    mat
  })

# Plot per cluster
plots <- map2(names(similarity_matrices), similarity_matrices, function(cluster_name, mat) {
  mat_df <- melt(mat)
  ggplot(mat_df, aes(Var1, Var2, fill = value)) +
    geom_tile() +
    scale_fill_gradient2(low = "white", high = "blue", midpoint = 0.5, na.value = "grey90") +
    labs(title = paste("Cluster:", cluster_name),
         x = "Pool Size", y = "Pool Size", fill = "Jaccard") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
})



```









